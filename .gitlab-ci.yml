stages:
  - validate
  - plan
  - approve
  - apply
  - deploy
  - cleanup

# Global variables
variables:
  AWS_REGION: "eu-central-1"
  EKS_CLUSTER_NAME: "my-eks-cluster"   # Your EKS cluster name
  TF_IN_AUTOMATION: "true"
  # AWS credentials (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, etc.) should be set as protected CI/CD variables

cache:
  key: terraform
  paths:
    - .terraform/

##################################
# 1) Validate Terraform
##################################
terraform-validate:
  stage: validate
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  script:
    - terraform init -backend=false
    - terraform validate
  only:
    - merge_requests
    - main

##################################
# 2) Terraform Plan
##################################
terraform-plan:
  stage: plan
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  script:
    - cd terraform
    - terraform init
    - terraform plan -var-file=terraform.tfvars -out=tfplan
  artifacts:
    paths:
      - terraform/tfplan
    when: always
  only:
    - merge_requests
    - main

##################################
# 3) Terraform Apply
##################################
terraform-apply:
  stage: apply
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  needs:
    - job: terraform-plan
      artifacts: true
  script:
    - cd terraform
    - terraform init
    - terraform apply -auto-approve tfplan
  only:
    - main

##################################
# 4) Deploy Kubernetes Workloads to EKS
##################################
deploy-k8s:
  stage: deploy
  image: ubuntu:20.04
  script:
    - export DEBIAN_FRONTEND=noninteractive
    - apt-get update -y && apt-get install -y awscli curl
    - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    - chmod +x kubectl && mv kubectl /usr/local/bin/
    # Generate kubeconfig using AWS CLI; this usually writes to $HOME/.kube/config
    - aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
    # Ensure the kubeconfig uses v1beta1 for the exec plugin
    - export KUBECONFIG=$HOME/.kube/config
    - sed -i 's/v1alpha1/v1beta1/g' $KUBECONFIG
    - kubectl apply -f k8s/
  environment:
    name: production
    kubernetes:
      agent: eks-gitlab-agent
  only:
    - main

##################################
# 5) Deploy ECS Tasks via Ansible (Run on AWS)
##################################
deploy-ecs:
  stage: deploy
  image: willhallonline/ansible:alpine
  script:
    - apk update && apk add --no-cache python3 py3-pip openssh-client
    - pip3 install awscli
    # Export AWS_DEFAULT_REGION so that AWS CLI picks up the region for ECS commands
    - export AWS_DEFAULT_REGION=$AWS_REGION
    # Run the playbook using an inline inventory and local connection to avoid SSH attempts
    - ansible-playbook -i "localhost," -c local ansible/ecs-deploy.yaml
  only:
    - main

##################################
# 6) Rollback Mechanism (On Failure)
##################################
rollback:
  stage: cleanup
  when: on_failure
  image: hashicorp/terraform:latest
  script:
    - terraform init
    - terraform destroy -auto-approve
    - apk update && apk add --no-cache curl python3 py3-pip
    - pip3 install ansible awscli
    - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    - chmod +x kubectl && mv kubectl /usr/local/bin/
    - export DEBIAN_FRONTEND=noninteractive
    - apt-get update -y && apt-get install -y awscli
    - aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
    - export KUBECONFIG=$HOME/.kube/config
    - sed -i 's/v1alpha1/v1beta1/g' $KUBECONFIG
    - kubectl delete -f k8s/ || true
    - ansible-playbook -i "localhost," -c local ansible/ecs-deploy.yaml --extra-vars "rollback=true"
  only:
    - main
