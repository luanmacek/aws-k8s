stages:
  - validate
  - plan
  - approve
  - apply
  - deploy
  - cleanup

# Global variables
variables:
  AWS_REGION: "eu-central-1"
  EKS_CLUSTER_NAME: "my-eks-cluster"   # Set your EKS cluster name here
  TF_IN_AUTOMATION: "true"
  # Optional: If storing Terraform state in S3, you might have:
  # TF_BACKEND_CONFIG: "-backend-config=bucket=my-terraform-state-bucket -backend-config=region=eu-central-1"

cache:
  key: terraform
  paths:
    - .terraform/

##################################
# 1) Validate Terraform
##################################
terraform-validate:
  stage: validate
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  script:
    - terraform init -backend=false
    - terraform validate
  only:
    - merge_requests
    - main

terraform-plan:
  stage: plan
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  script:
    - cd terraform
    - terraform init
    - terraform plan -var-file=terraform.tfvars -out=tfplan
  artifacts:
    paths:
      - terraform/tfplan
    when: always
  only:
    - merge_requests
    - main

terraform-apply:
  stage: apply
  image:
    name: hashicorp/terraform:latest
    entrypoint: [""]
  needs:
    - job: terraform-plan
      artifacts: true
  script:
    - cd terraform
    - terraform init
    - terraform apply -auto-approve tfplan
  only:
    - main

##################################
# 5) Deploy Kubernetes Workloads to EKS
##################################
deploy-k8s:
  stage: deploy
  image:
    name: bitnami/kubectl:latest
    entrypoint: [""]
  script:
    # Install AWS CLI to generate kubeconfig
    - apt-get update && apt-get install -y awscli
    # Generate kubeconfig using your AWS credentials
    - aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
    - kubectl apply -f k8s/
  environment:
    name: production
    kubernetes:
      agent: eks-gitlab-agent
  only:
    - main

##################################
# 6) Deploy ECS Tasks via Ansible (Run on AWS)
##################################
deploy-ecs:
  stage: deploy
  image: willhallonline/ansible:alpine
  script:
    # Use your Ansible inventory that targets your AWS host(s)
    - ansible-playbook -i inventory ansible/ecs-deploy.yaml
  only:
    - main

##################################
# Rollback Mechanism (On Failure)
##################################
rollback:
  stage: cleanup
  when: on_failure
  image: hashicorp/terraform:latest
  script:
    # 1) Destroy Terraform-managed infrastructure
    - terraform init
    - terraform destroy -auto-approve
    # 2) Install dependencies to run kubectl and ansible
    - apk update && apk add --no-cache curl python3 py3-pip
    - pip3 install ansible
    # 3) Install kubectl
    - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    - chmod +x kubectl
    - mv kubectl /usr/local/bin/
    # 4) If AWS credentials are available, generate kubeconfig and remove K8s resources
    - apt-get update && apt-get install -y awscli
    - aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
    - kubectl delete -f k8s/ || true
    # 5) Roll back ECS tasks using your inventory
    - ansible-playbook -i inventory ansible/ecs-deploy.yaml --extra-vars "rollback=true"
  only:
    - main
